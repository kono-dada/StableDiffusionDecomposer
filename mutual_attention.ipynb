{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import callback, my_attn, my_pipeline\n",
    "importlib.reload(callback)\n",
    "importlib.reload(my_attn)\n",
    "importlib.reload(my_pipeline)\n",
    "from my_pipeline import run_with_attn_replacement, MutualAttention\n",
    "from diffusers import StableDiffusionPipeline, DDIMInverseScheduler, DDIMScheduler\n",
    "from my_attn import prep_unet_attention\n",
    "from tqdm.notebook import tqdm\n",
    "from callback import QKVRecordCallback\n",
    "from utils import load_image, img_to_latents, concat_img \n",
    "from callback import ATTN_BLOCKS\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "dtype = torch.float16\n",
    "model_dir = '/home/tom/fshare/models/Stability-AI/stable-diffusion-2-1'\n",
    "# model_dir = '/home/tom/fshare/models/runwayml/stable-diffusion-v1-5'\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_dir, safety_checker=None, torch_dtype=dtype)\n",
    "\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inversion_steps = 999\n",
    "prep_unet_attention(pipe.unet)\n",
    "imgname = 'images/kitten.jpg'\n",
    "input_img = load_image(\n",
    "    imgname,\n",
    "    target_size=(512, 512)\n",
    ").to(device=device, dtype=dtype)\n",
    "prompt_inversion = ''\n",
    "\n",
    "with torch.no_grad():\n",
    "    pipe.scheduler = DDIMInverseScheduler.from_pretrained(\n",
    "        '/home/tom/fshare/models/Stability-AI/stable-diffusion-2-1', subfolder='scheduler')\n",
    "    latents = img_to_latents(input_img, pipe.vae)  # VAE latent\n",
    "    inv_latents, _ = pipe(\n",
    "        prompt=prompt_inversion,\n",
    "        guidance_scale=1,\n",
    "        width=input_img.shape[-1],\n",
    "        height=input_img.shape[-2],\n",
    "        output_type='latent',\n",
    "        return_dict=False,\n",
    "        num_inference_steps=num_inversion_steps,\n",
    "        latents=latents,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_attn = MutualAttention(pipe)\n",
    "result = mutual_attn(\n",
    "    replaced_attn_indice=[12],\n",
    "    replaced_qkv=['k', 'v'],\n",
    "    end=500,\n",
    "    prompt='A kitten is sitting in a basket on a branch',\n",
    "    ref_prompt='A kitten is sitting in a basket on a branch',\n",
    "    latents=inv_latents,\n",
    "    ref_latents=inv_latents,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
